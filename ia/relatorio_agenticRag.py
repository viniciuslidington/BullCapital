
import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
import pdfplumber
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
import openai
import time
from typing import List, Dict, Optional
import logging

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RelatorioAnualRAG:
    def __init__(self, openai_api_key: str):
        """
        Inicializa o agente RAG para an√°lise de relat√≥rios anuais da WEG
        """
        self.openai_api_key = openai_api_key
        self.session = requests.Session()
        # Headers otimizados para Mac e Chrome
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
        })
        
        # Configuracao OpenAI
        openai.api_key = openai_api_key
        self.embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        self.llm = ChatOpenAI(
            openai_api_key=openai_api_key,
            model_name="gpt-3.5-turbo",
            temperature=0.3
        )
        
        self.vector_store = None
        self.qa_chain = None
        
    def buscar_documentos_weg(self) -> List[Dict[str, str]]:
        """
        Busca documentos da WEG na p√°gina inicial com abordagem mais flex√≠vel
        """
        try:
            logger.info("Acessando p√°gina inicial da WEG...")
            
            url_inicial = "https://ri.weg.net/"
            response = self.session.get(url_inicial, timeout=15)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')
            
            documentos_encontrados = []
            
            #  buscar todos os links que contenham palavras-chave
            logger.info("Procurando links com palavras-chave")
            
            # Palavras-chave comuns em documentos financeiros
            keywords = [
                'release', 'resultado', 'demonstra√ß√£o', 'financeira', 'apresenta√ß√£o',
                'itr', 'dfp', 'balan√ßo', 'lucro', 'receita'
            ]
            
            # Procurar todos os links na p√°gina
            links = soup.find_all('a', href=True)
            
            for link in links:
                href = link['href']
                text = link.get_text().strip().lower()
                
                # Verificar se √© PDF e cont√©m palavras-chave
                if (href.lower().endswith('.pdf') or 'pdf' in href.lower()) and \
                   (any(keyword in text for keyword in keywords) or 
                    any(keyword in href.lower() for keyword in keywords)):
                    
                    full_url = urljoin(url_inicial, href)
                    nome_original = link.get_text().strip() or "Documento Financeiro"
                    
                    documentos_encontrados.append({
                        'url': full_url,
                        'nome': nome_original
                    })
                    logger.info(f"Documento encontrado: {nome_original}")
            
            # Abordagem 2: Se n√£o encontrou nada, procurar por qualquer PDF
            if not documentos_encontrados:
                logger.info("Nenhum documento espec√≠fico encontrado, buscando todos os PDFs...")
                for link in links:
                    href = link['href']
                    if href.lower().endswith('.pdf'):
                        full_url = urljoin(url_inicial, href)
                        nome_original = link.get_text().strip() or "Documento PDF"
                        
                        documentos_encontrados.append({
                            'url': full_url,
                            'nome': nome_original
                        })
                        logger.info(f"PDF gen√©rico encontrado: {nome_original}")
            
            # Remover duplicatas
            urls_unicos = {}
            for doc in documentos_encontrados:
                urls_unicos[doc['url']] = doc
            
            documentos_unicos = list(urls_unicos.values())
            logger.info(f"Total de documentos √∫nicos encontrados: {len(documentos_unicos)}")
            
            # Limitar a 5 documentos para evitar sobrecarga
            return documentos_unicos[:5]
            
        except Exception as e:
            logger.error(f"Erro ao buscar documentos: {str(e)}")
            return []
    
    def baixar_relatorio(self, url: str, pasta_destino: str = "relatorios") -> Optional[str]:
        """Baixando um relat√≥rio PDF"""
        try:
            os.makedirs(pasta_destino, exist_ok=True)
            
            parsed_url = urlparse(url)
            filename = os.path.basename(parsed_url.path)
            
            if not filename or '.' not in filename:
                filename = f"documento_{int(time.time())}.pdf"
            
            filepath = os.path.join(pasta_destino, filename)
            
            logger.info(f"Baixando: {url}")
            
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            # verifico se eh pdf
            content_type = response.headers.get('content-type', '')
            if 'application/pdf' not in content_type and not url.lower().endswith('.pdf'):
                logger.warning(f"Esse arquivo n√£o √© um PDFF: {content_type}")
                return None
            
            with open(filepath, 'wb') as f:
                f.write(response.content)
            
            logger.info(f"Documento salvo em: {filepath}")
            return filepath
            
        except Exception as e:
            logger.error(f"Erro ao baixar {url}: {str(e)}")
            return None

    def extrair_texto_pdf(self, filepath: str) -> str:
        """Extrai texto de um arquivo PDF"""
        try:
            logger.info(f"Extraindo texto de: {filepath}")
            texto_completo = ""
            
            with pdfplumber.open(filepath) as pdf:
                for page in pdf.pages:
                    texto = page.extract_text()
                    if texto:
                        texto_completo += texto + "\n\n"
            
            logger.info(f"Extra√≠do: {len(texto_completo)} caracteres")
            return texto_completo
            
        except Exception as e:
            logger.error(f"Erro ao extrair texto: {str(e)}")
            return ""

    def criar_vector_store(self, textos: List[str]) -> None:
        """Cria o vector store para o RAG"""
        try:
            logger.info("Criando vector store...")
            
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200,
                separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
            )
            
            all_chunks = []
            for texto in textos:
                chunks = text_splitter.split_text(texto)
                all_chunks.extend(chunks)
            
            logger.info(f"Dividido em {len(all_chunks)} chunks")
            
            # Criar vector store
            self.vector_store = FAISS.from_texts(all_chunks, self.embeddings)
            
            prompt_template = """
            Voc√™ √© um especialista financeiro que analisa documentos corporativos da WEG Motors. 
            Use as seguintes partes dos documentos para responder √† pergunta. 
            Se n√£o souber, diga que n√£o encontrou informa√ß√µes suficientes.
            Sempre que poss√≠vel, mencione valores num√©ricos e dados concretos.

            {context}

            Pergunta: {question}
            Resposta:"""
            
            PROMPT = PromptTemplate(
                template=prompt_template,
                input_variables=["context", "question"]
            )
            
            self.qa_chain = RetrievalQA.from_chain_type(
                llm=self.llm,
                chain_type="stuff",
                retriever=self.vector_store.as_retriever(search_kwargs={"k": 5}),
                chain_type_kwargs={"prompt": PROMPT},
                return_source_documents=True
            )
            
            logger.info("Vector store criado com sucesso!")
            
        except Exception as e:
            logger.error(f"Erro ao criar vector store: {str(e)}")
            raise

    def processar_documentos_weg(self) -> bool:
        """Processa documentos da WEG com abordagem mais robusta"""
        try:
            logger.info("Iniciando busca por documentos da WEG...")
            
            # 1. Buscar documentos automaticamente
            documentos = self.buscar_documentos_weg()
            
            if not documentos:
                logger.warning("Nenhum documento encontrado automaticamente")
                logger.info("Tentando URL conhecido")
                documentos = [{
                    'url': 'https://api.mziq.com/mzfilemanager/v2/d/50c1bd3e-8ac6-42d9-884f-b9d69f690602/8a3640f7-490e-5cfd-4cd5-bd9de3f4ac5a?origin=1',
                    'nome': 'Release de Resultados WEG'
                }]
            
            logger.info(f"Documentos encontrados: {len(documentos)}")
            
            # 2. Baixar documentos
            textos = []
            for i, doc in enumerate(documentos):
                logger.info(f"[{i+1}/{len(documentos)}] Processando: {doc['nome']}")
                filepath = self.baixar_relatorio(doc['url'])
                
                if filepath:
                    texto = self.extrair_texto_pdf(filepath)
                    if texto and len(texto) > 100:  
                        textos.append(texto)
                        logger.info(f"‚úì Texto extra√≠do de {doc['nome']} ({len(texto)} caracteres)")
                    else:
                        logger.warning(f"‚úó Texto muito curto ou vazio em {doc['nome']}")
                else:
                    logger.warning(f"‚úó Falha ao baixar {doc['nome']}")
                
                time.sleep(1)  
            
            if not textos:
                logger.error("Nenhum texto foi extra√≠do dos documentos")
                return False
            
            logger.info(f"Processando {len(textos)} documentos com conte√∫do")
            
            # 3. Criar vector store
            self.criar_vector_store(textos)
            return True
            
        except Exception as e:
            logger.error(f"Erro ao processar documentos: {str(e)}")
            return False

    def perguntar(self, pergunta: str) -> Dict[str, any]:
        """Faz uma pergunta sobre os documentos"""
        if not self.qa_chain:
            return {"erro": "Sistema n√£o inicializado. Execute processar_documentos_weg() primeiro."}
        
        try:
            logger.info(f"Pergunta: {pergunta}")
            resultado = self.qa_chain({"query": pergunta})
            
            return {
                "resposta": resultado["result"],
                "fontes": [doc.page_content[:200] + "..." for doc in resultado["source_documents"]]
            }
            
        except Exception as e:
            logger.error(f"Erro ao responder: {str(e)}")
            return {"erro": f"Erro ao processar pergunta: {str(e)}"}

# Exemplo de uso
def main():
    OPENAI_API_KEY= "insira uma chave aq pfvr"

    
    rag = RelatorioAnualRAG(OPENAI_API_KEY)
    
    print("üîç Processando documentos da WEG (abordagem robusta)...")
    if rag.processar_documentos_weg():
        print("‚úÖ Processamento conclu√≠do com sucesso!")
        print("\nüí¨ Voc√™ pode fazer perguntas como:")
        print("   ‚Ä¢ Quais s√£o os principais resultados financeiros?")
        print("   ‚Ä¢ Qual foi o lucro l√≠quido nos √∫ltimos per√≠odos?")
        print("   ‚Ä¢ Como est√° o desempenho das exporta√ß√µes?")
        print("   ‚Ä¢ Quais s√£o os principais indicadores de sustentabilidade?")
        print("   ‚Ä¢ Qual foi o crescimento da receita?")
        print("\n(Digite 'sair' para encerrar)\n")
        
        while True:
            try:
                pergunta = input("Pergunta: ").strip()
                if pergunta.lower() in ['sair', 'exit', 'quit', '']:
                    break
                    
                if pergunta:
                    resposta = rag.perguntar(pergunta)
                    if "erro" in resposta:
                        print(f"‚ùå {resposta['erro']}")
                    else:
                        print(f"‚úÖ {resposta['resposta']}")
                        print(f"üìö Fontes: {len(resposta['fontes'])} trechos relevantes encontrados")
                    print("-" * 80)
            except KeyboardInterrupt:
                print("\nüëã At√© logo!")
                break
            except Exception as e:
                print(f"‚ùå Erro: {str(e)}")
    else:
        print("‚ùå Falha no processamento - nenhum documento encontrado")

if __name__ == "__main__":
    main()